{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a843c23b030e4822b575f3a4a7cebcd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb8e3c4ee1134cde871a2f7f711bd747",
              "IPY_MODEL_3dab172fc31e4b7a9e4793f33b3a0f51",
              "IPY_MODEL_b5049cff85b24d9e9ebfd5a6dccc8703"
            ],
            "layout": "IPY_MODEL_ba65dd7bcdb443ce8a7b626f148b076e"
          }
        },
        "eb8e3c4ee1134cde871a2f7f711bd747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_020e668f99584311ac09417f34ad6290",
            "placeholder": "​",
            "style": "IPY_MODEL_0a4440b125b44f68977213dd3b42be8d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3dab172fc31e4b7a9e4793f33b3a0f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d0ba76ad36c4f6bad80ce75b0e042c7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52bff979aa3f40dca50f45dafc5557e2",
            "value": 2
          }
        },
        "b5049cff85b24d9e9ebfd5a6dccc8703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6407641ec3c4a27b6728e6880465f59",
            "placeholder": "​",
            "style": "IPY_MODEL_5e1983e9bb0e47ad9c5badff4379d10b",
            "value": " 2/2 [01:09&lt;00:00, 32.63s/it]"
          }
        },
        "ba65dd7bcdb443ce8a7b626f148b076e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "020e668f99584311ac09417f34ad6290": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a4440b125b44f68977213dd3b42be8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d0ba76ad36c4f6bad80ce75b0e042c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52bff979aa3f40dca50f45dafc5557e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6407641ec3c4a27b6728e6880465f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e1983e9bb0e47ad9c5badff4379d10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41aa6e66be2f493dbe3cdd299f9300bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9990cbf038ae41ed9e12922d6df83c85",
              "IPY_MODEL_83dcf5dc97d343728f5ab280af0120ef",
              "IPY_MODEL_d8240c48fd664301a4c538fe910867dd"
            ],
            "layout": "IPY_MODEL_843d15c52a084173b6cc3b4dd5f2ab44"
          }
        },
        "9990cbf038ae41ed9e12922d6df83c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8937c094a2a840318c7fd0ee0a577f69",
            "placeholder": "​",
            "style": "IPY_MODEL_d8cc52c6eb2942afa493311aeb14194e",
            "value": "Generating train split: "
          }
        },
        "83dcf5dc97d343728f5ab280af0120ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59b31627690b461e8fb0dade46afb660",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa94192a1425440285903a47c9622046",
            "value": 1
          }
        },
        "d8240c48fd664301a4c538fe910867dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eacd6b19e6694ae4938ba2cd6f69f283",
            "placeholder": "​",
            "style": "IPY_MODEL_e7e4ad7169ba43159cbaaa119355a46e",
            "value": " 414/0 [00:01&lt;00:00, 226.44 examples/s]"
          }
        },
        "843d15c52a084173b6cc3b4dd5f2ab44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8937c094a2a840318c7fd0ee0a577f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8cc52c6eb2942afa493311aeb14194e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59b31627690b461e8fb0dade46afb660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "aa94192a1425440285903a47c9622046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eacd6b19e6694ae4938ba2cd6f69f283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7e4ad7169ba43159cbaaa119355a46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1f6b028f7f2471ea97c7c50b598ed29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7934fe8fe8924fdd8263a6aaef952c59",
              "IPY_MODEL_d2e20079ae184d5d8ee26baec56a4d44",
              "IPY_MODEL_8ed613fa7009441a81f5779c0db46a3c"
            ],
            "layout": "IPY_MODEL_e0b4b04ff7c34b239e3e9d64ab797bbe"
          }
        },
        "7934fe8fe8924fdd8263a6aaef952c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b5032c92a5b4babaf322eedffaa3c77",
            "placeholder": "​",
            "style": "IPY_MODEL_64311cc8c4794181809c3ea26efe88a0",
            "value": "Generating train split: "
          }
        },
        "d2e20079ae184d5d8ee26baec56a4d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52d8942c67394ceb907e049180ba357f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e88610ef4e4a45528cbb3e009cf7cc19",
            "value": 1
          }
        },
        "8ed613fa7009441a81f5779c0db46a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e992266bd2814877944ff5809637b916",
            "placeholder": "​",
            "style": "IPY_MODEL_302802b799624aeaa422cdb990ca881e",
            "value": " 54/0 [00:00&lt;00:00,  5.38 examples/s]"
          }
        },
        "e0b4b04ff7c34b239e3e9d64ab797bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b5032c92a5b4babaf322eedffaa3c77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64311cc8c4794181809c3ea26efe88a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52d8942c67394ceb907e049180ba357f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e88610ef4e4a45528cbb3e009cf7cc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e992266bd2814877944ff5809637b916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "302802b799624aeaa422cdb990ca881e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatemafaria142/Impact-of-Instruction-Tuning-in-Biomedical-Language-Processing-Using-Different-LLMs/blob/main/Biomedical_Language_Processing_using_Mistral_7B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Install Required Packages**"
      ],
      "metadata": {
        "id": "iEkm_Q9AGgTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate peft bitsandbytes transformers trl datasets torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp-9Dpjn8fAD",
        "outputId": "b3fe2934-8263-4822-df7b-20782fa4a1cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft\n",
            "  Downloading peft-0.7.1-py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting trl\n",
            "  Downloading trl-0.7.9-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Collecting tyro>=0.5.11 (from trl)\n",
            "  Downloading tyro-0.6.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.9/78.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.0)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
            "  Downloading shtab-1.6.5-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Installing collected packages: shtab, docstring-parser, dill, multiprocess, bitsandbytes, tyro, accelerate, datasets, trl, peft\n",
            "Successfully installed accelerate-0.26.1 bitsandbytes-0.42.0 datasets-2.16.1 dill-0.3.7 docstring-parser-0.15 multiprocess-0.70.15 peft-0.7.1 shtab-1.6.5 trl-0.7.9 tyro-0.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset Link:** https://huggingface.co/datasets/nlpie/Llama2-MedTuned-Instructions?row=0"
      ],
      "metadata": {
        "id": "ck_5U-vIq7zW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "instruct_tune_dataset = load_dataset(\"nlpie/Llama2-MedTuned-Instructions\")"
      ],
      "metadata": {
        "id": "DI1G_zS8PWh9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset structure**\n",
        "\n",
        "* The dataset contains three different columns."
      ],
      "metadata": {
        "id": "VmAvZLhkrY6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruct_tune_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfDpPbAyTHff",
        "outputId": "1e682851-e1ad-41ca-fc5d-3d999bb0befd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['instruction', 'input', 'output'],\n",
              "        num_rows: 205048\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display information for 5 data points from the 'train' split\n",
        "num_samples_to_show = 5\n",
        "for i in range(num_samples_to_show):\n",
        "    data = instruct_tune_dataset['train'][i]\n",
        "    print(f\"Data Point {i + 1}:\")\n",
        "    print(\"Instruction:\", data['instruction'])\n",
        "    print(\"Input:\", data['input'])\n",
        "    print(\"Output:\", data['output'])\n",
        "    print(\"\\n-----------------------------\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NLAaGoiZSRA",
        "outputId": "20aaae9b-906d-4ac3-ae51-9c154b90a349"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Point 1:\n",
            "Instruction: Your goal is to determine the relationship between the two provided clinical sentences and classify them into one of the following categories:\n",
            "Contradiction: If the two sentences contradict each other.\n",
            "Neutral: If the two sentences are unrelated to each other.\n",
            "Entailment: If one of the sentences logically entails the other.\n",
            "Input: Sentence 1: For his hypotension, autonomic testing confirmed orthostatic hypotension.\n",
            "Sentence 2: the patient has orthostatic hypotension\n",
            "Output: Entailment\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Data Point 2:\n",
            "Instruction: In the provided text, your objective is to recognize and tag gene-related Named Entities using the BIO labeling scheme. Start by labeling the initial word of a gene-related phrase as B (Begin), and then mark the following words in the same phrase as I (Inner). Any words not constituting gene-related entities should receive an O label.\n",
            "Input: The first product of ascorbate oxidation , the ascorbate free radical ( AFR ) , acts in biological systems mainly as an oxidant , and through its role in the plasma membrane redox system exerts different effects on the cell .\n",
            "Output: The : O\n",
            "first : O\n",
            "product : O\n",
            "of : O\n",
            "ascorbate : O\n",
            "oxidation : O\n",
            ", : O\n",
            "the : O\n",
            "ascorbate : O\n",
            "free : O\n",
            "radical : O\n",
            "( : O\n",
            "AFR : O\n",
            ") : O\n",
            ", : O\n",
            "acts : O\n",
            "in : O\n",
            "biological : O\n",
            "systems : O\n",
            "mainly : O\n",
            "as : O\n",
            "an : O\n",
            "oxidant : O\n",
            ", : O\n",
            "and : O\n",
            "through : O\n",
            "its : O\n",
            "role : O\n",
            "in : O\n",
            "the : O\n",
            "plasma : O\n",
            "membrane : O\n",
            "redox : O\n",
            "system : O\n",
            "exerts : O\n",
            "different : O\n",
            "effects : O\n",
            "on : O\n",
            "the : O\n",
            "cell : O\n",
            ". : O\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Data Point 3:\n",
            "Instruction: If you have expertise in healthcare, assist users by addressing their medical questions and concerns.\n",
            "Input: i am having acute gas problem which i am feeling  and my bp has raised to 130/90, During  this time i have palpitation and i feel there is a missing pulse . Kindly guide me to overcome this problem.On the other hand if there is no gas in my stomach the aforesaid problems are not occuring.\n",
            "Output: Dear-thanks for using our service and will try to help you with my medical advice. You might be experiencing intestinal gas from food that you are eating as some vegetables like broccoli, cauliflower and that can make your heart rate faster too. However, the blood pressure is high, which can be the primary problem or secondary to other things like salt in your diet. I recommend you to watch what your eat, control salt, Chat Doctor.  That will help your blood pressure and the intestinal movements too. Avoid soda and caffeine too. I hope that my advice has been helpful.\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Data Point 4:\n",
            "Instruction: Being a doctor, your task is to answer the medical questions based on the patient's description.\n",
            "Determine the relation between the two medical terms.\n",
            "Input: ###Question: What is the relation between Household Activity and Does not bath self (finding) ?\n",
            "Output: ###Answer: Does not bath self (finding) interprets: Household Activity\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Data Point 5:\n",
            "Instruction: In your role as a medical professional, address the user's medical questions and concerns.\n",
            "Input: Hi I have the last few weeks had a sharp pain in my upper abdoman (centre) and a dull pain on the side, changing from left to right..just under my chest/ribs I also feel dizzy and like im a bit drunk... I have see a doctor who says im aneamic and also referred me for a gastroscopy but im really worried its somethign that can t be seen with this camera..\n",
            "Output: Thank you. Upper abdominal pain with anemia indicate some disease of upper GIT.peptic ulcer disease is the most possibility. Have you any history of vomiting out of blood or passage of black tarry stool ? Gastroscopy is confirmatory for this. Serology for h.pylori may be done. If these are inconclusive then other in. Should be considered like USG of abdomen. Dizziness is due to anemia. You have to check He level also.\n",
            "\n",
            "-----------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **We will use just a small subset of the data for this training example**"
      ],
      "metadata": {
        "id": "HNKsQDzlilSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruct_tune_dataset[\"train\"] = instruct_tune_dataset[\"train\"].select(range(1500))\n",
        "instruct_tune_dataset[\"test\"] = instruct_tune_dataset[\"train\"].select(range(200))"
      ],
      "metadata": {
        "id": "d-fQF_ZngrHx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruct_tune_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs4dDoFUKvNI",
        "outputId": "74a72fc3-1ea9-4e1c-f286-81d37ba880f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['instruction', 'input', 'output'],\n",
              "        num_rows: 1500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['instruction', 'input', 'output'],\n",
              "        num_rows: 200\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''''\n",
        "def create_prompt(sample):\n",
        "  \"\"\"\n",
        "  Update the prompt template:\n",
        "  Combine both the prompt and input into a single column.\n",
        "\n",
        "  \"\"\"\n",
        "  bos_token = \"<s>\"\n",
        "  original_system_message = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
        "  system_message = \"Use the provided input to create an instruction that could have been used to generate the response with an LLM.\"\n",
        "  response = sample[\"output\"].replace(original_system_message, \"\").replace(\"\\n\\n### Instruction\\n\", \"\").replace(\"\\n### Response\\n\", \"\").strip()\n",
        "  input = sample[\"instruction\"]\n",
        "  eos_token = \"</s>\"\n",
        "\n",
        "  full_prompt = \"\"\n",
        "  full_prompt += bos_token\n",
        "  full_prompt += \"### Instruction:\"\n",
        "  full_prompt += \"\\n\" + system_message\n",
        "  full_prompt += \"\\n\\n### Input:\"\n",
        "  full_prompt += \"\\n\" + input\n",
        "  full_prompt += \"\\n\\n### Response:\"\n",
        "  full_prompt += \"\\n\" + response\n",
        "  full_prompt += eos_token\n",
        "\n",
        "  return full_prompt\n",
        "\n",
        "  create_prompt(instruct_tune_dataset[\"train\"][0])\n",
        "  ''''"
      ],
      "metadata": {
        "id": "ZYLl8EJmTRL2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt(sample):\n",
        "  \"\"\"\n",
        "  Update the prompt template:\n",
        "  Combine both the prompt and input into a single column.\n",
        "\n",
        "  \"\"\"\n",
        "  bos_token = \"<s>\"\n",
        "\n",
        "  eos_token = \"</s>\"\n",
        "\n",
        "  full_prompt = \"\"\n",
        "  full_prompt += bos_token\n",
        "  full_prompt += \"### Instruction:\"\n",
        "  full_prompt += \"\\n\" + sample[\"instruction\"]\n",
        "  full_prompt += \"\\n\\n### Input:\"\n",
        "  full_prompt += \"\\n\" + sample[\"input\"]\n",
        "  full_prompt += \"\\n\\n### Response:\"\n",
        "  full_prompt += \"\\n\" + sample[\"output\"]\n",
        "  full_prompt += eos_token\n",
        "\n",
        "  return full_prompt"
      ],
      "metadata": {
        "id": "pfQ4941V8Ctm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_prompt(instruct_tune_dataset[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "TPhFXC088j-o",
        "outputId": "be83e557-ba12-40de-807f-2d2c42fe16ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>### Instruction:\\nYour goal is to determine the relationship between the two provided clinical sentences and classify them into one of the following categories:\\nContradiction: If the two sentences contradict each other.\\nNeutral: If the two sentences are unrelated to each other.\\nEntailment: If one of the sentences logically entails the other.\\n\\n### Input:\\nSentence 1: For his hypotension, autonomic testing confirmed orthostatic hypotension.\\nSentence 2: the patient has orthostatic hypotension\\n\\n### Response:\\nEntailment</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_prompt(instruct_tune_dataset[\"train\"][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "ppraZp5B9F3I",
        "outputId": "8968376a-46da-4cd6-b44e-559fc6b25c1b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>### Instruction:\\nIf you have expertise in healthcare, assist users by addressing their medical questions and concerns.\\n\\n### Input:\\ni am having acute gas problem which i am feeling  and my bp has raised to 130/90, During  this time i have palpitation and i feel there is a missing pulse . Kindly guide me to overcome this problem.On the other hand if there is no gas in my stomach the aforesaid problems are not occuring.\\n\\n### Response:\\nDear-thanks for using our service and will try to help you with my medical advice. You might be experiencing intestinal gas from food that you are eating as some vegetables like broccoli, cauliflower and that can make your heart rate faster too. However, the blood pressure is high, which can be the primary problem or secondary to other things like salt in your diet. I recommend you to watch what your eat, control salt, Chat Doctor.  That will help your blood pressure and the intestinal movements too. Avoid soda and caffeine too. I hope that my advice has been helpful.</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_prompt(instruct_tune_dataset[\"train\"][5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "FSuiP6u49NXJ",
        "outputId": "0b6c7095-a693-4588-d648-dc88de677ee0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>### Instruction:\\nAs a healthcare expert, provide answers to medical inquiries based on the information given by the user.\\n\\n### Input:\\ni am scheduled for shock wave treatment for kidney stones and blockage. I understand they have more than 1 type of lithrotipsy machines, the ones that use water and those that use padded cushions. Which ones are recommended  and why? Do they both use x-rays to guide them? I know some use ultrasound. Thank you\\n\\n### Response:\\nEndoscopic lithography refers to the visualization of a calculus in the urinary tract and the simultaneous application of energy to fragment the stone or stones into either extractable or passable pieces. Many calculi in the upper urinary tract are treated with extracorporeal shockwave lithography (ESL). However, for stones that are poor candidates for this modality, endoscopic therapy is indicated. Ureteroscopy is the most common means of visualizing an upper urinary tract calculus. In addition, percutaneous techniques (e.g., percutaneous entomology) can also be used. Depending on stone size and location and associated ureteral obstruction, various treatments can be used</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Initializing the Model**\n",
        "* Load the model using a 4-bit configuration, employing double quantization, and set bfloat16 as the compute data type.\n",
        "\n",
        "* Notably, we opt for the instruct-tuned model in this instance rather than the base model. It's worth mentioning that fine-tuning a base model necessitates a more substantial amount of data!"
      ],
      "metadata": {
        "id": "4qjy9PYUaY3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=\"float16\", bnb_4bit_use_double_quant=True\n",
        "    )\n"
      ],
      "metadata": {
        "id": "qRb5keMJB7wr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1"
      ],
      "metadata": {
        "id": "BAKb1MQOXzG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mode_id = \"mistralai/Mistral-7B-Instruct-v0.1\""
      ],
      "metadata": {
        "id": "LY1mIvbkCJij"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        mode_id, quantization_config=bnb_config, device_map=\"auto\", use_cache=False\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a843c23b030e4822b575f3a4a7cebcd7",
            "eb8e3c4ee1134cde871a2f7f711bd747",
            "3dab172fc31e4b7a9e4793f33b3a0f51",
            "b5049cff85b24d9e9ebfd5a6dccc8703",
            "ba65dd7bcdb443ce8a7b626f148b076e",
            "020e668f99584311ac09417f34ad6290",
            "0a4440b125b44f68977213dd3b42be8d",
            "1d0ba76ad36c4f6bad80ce75b0e042c7",
            "52bff979aa3f40dca50f45dafc5557e2",
            "b6407641ec3c4a27b6728e6880465f59",
            "5e1983e9bb0e47ad9c5badff4379d10b"
          ]
        },
        "id": "ZbaaN_VdWABp",
        "outputId": "70d12f83-4d01-4891-f42a-656209a176cd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a843c23b030e4822b575f3a4a7cebcd7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "id": "9TzTWLD2WBZV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Let's example how well the model does at this task currently:**"
      ],
      "metadata": {
        "id": "dlQxPyiKi51k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(prompt, model):\n",
        "  encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
        "  model_inputs = encoded_input.to('cuda')\n",
        "\n",
        "  generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
        "\n",
        "  return decoded_output[0].replace(prompt, \"\")"
      ],
      "metadata": {
        "id": "wRWhXzXrc41b"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"### Instruction:\\nYour goal is to determine the relationship between the two provided clinical sentences and classify them into one of the following categories: Contradiction: If the two sentences contradict each other. Neutral: If the two sentences are unrelated to each other. Entailment: If one of the sentences logically entails the other.### Input:\\nSentence 1: For his hypotension, autonomic testing confirmed orthostatic hypotension. Sentence 2: the patient has orthostatic hypotension\\n\\n### Response:\""
      ],
      "metadata": {
        "id": "JF7ISvKjdA6h"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_response(prompt, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "p1q6rxvU61hO",
        "outputId": "42b9e01b-7b3e-418e-b404-e1257fd2499d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> \\nNeutral</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setting up the Training**\n",
        "we will be using the `huggingface` and the `peft` library!"
      ],
      "metadata": {
        "id": "g-Vs5Dc3DdY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "peft_config = LoraConfig(r=8, lora_alpha=16, lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\")\n"
      ],
      "metadata": {
        "id": "SQulqDzjd0gD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* we need to prepare the model to be trained in 4bit so we will use the  **`prepare_model_for_kbit_training`** function from peft\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1SWl1MgjDrXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = prepare_model_for_kbit_training(model)\n",
        "model = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "id": "bcco3ITVd486"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Hyperparameters**\n",
        "The choice of hyperparameters is contingent upon the desired training duration. Pay special attention to the following key factors:\n",
        "\n",
        "* `num_train_epochs/max_steps:` Dictates the number of iterations over the data. Exercise caution, as an excessive number may lead to overfitting!\n",
        "\n",
        "* `learning_rate:` Governs the convergence speed of the model. Adjust this parameter judiciously for optimal results."
      ],
      "metadata": {
        "id": "go8_nVq7jO9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "output_model= \"mistral_biomedical_generation\"\n",
        "training_arguments = TrainingArguments(\n",
        "        output_dir=output_model,\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        optim=\"paged_adamw_32bit\",\n",
        "        learning_rate=2e-4,\n",
        "        lr_scheduler_type=\"cosine\",\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_steps=10,\n",
        "        num_train_epochs=1,\n",
        "        max_steps=50,\n",
        "        fp16=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "lm65iOf5DOx3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setting up the trainer**\n",
        "\n",
        "`max_seq_length`: Context window size\n"
      ],
      "metadata": {
        "id": "Gz6Vhh4WFpMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "max_seq_length = 1024\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "  model=model,\n",
        "  peft_config=peft_config,\n",
        "  max_seq_length=max_seq_length,\n",
        "  tokenizer=tokenizer,\n",
        "  packing=True,\n",
        "  formatting_func=create_prompt, # this will aplly the create_prompt mapping to all training and test dataset\n",
        "  args=training_arguments,\n",
        "  train_dataset=instruct_tune_dataset[\"train\"],\n",
        "  eval_dataset=instruct_tune_dataset[\"test\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "41aa6e66be2f493dbe3cdd299f9300bb",
            "9990cbf038ae41ed9e12922d6df83c85",
            "83dcf5dc97d343728f5ab280af0120ef",
            "d8240c48fd664301a4c538fe910867dd",
            "843d15c52a084173b6cc3b4dd5f2ab44",
            "8937c094a2a840318c7fd0ee0a577f69",
            "d8cc52c6eb2942afa493311aeb14194e",
            "59b31627690b461e8fb0dade46afb660",
            "aa94192a1425440285903a47c9622046",
            "eacd6b19e6694ae4938ba2cd6f69f283",
            "e7e4ad7169ba43159cbaaa119355a46e",
            "e1f6b028f7f2471ea97c7c50b598ed29",
            "7934fe8fe8924fdd8263a6aaef952c59",
            "d2e20079ae184d5d8ee26baec56a4d44",
            "8ed613fa7009441a81f5779c0db46a3c",
            "e0b4b04ff7c34b239e3e9d64ab797bbe",
            "1b5032c92a5b4babaf322eedffaa3c77",
            "64311cc8c4794181809c3ea26efe88a0",
            "52d8942c67394ceb907e049180ba357f",
            "e88610ef4e4a45528cbb3e009cf7cc19",
            "e992266bd2814877944ff5809637b916",
            "302802b799624aeaa422cdb990ca881e"
          ]
        },
        "id": "UyyNtDrmeAkc",
        "outputId": "9e1fde6c-9548-4111-f38b-8c12ade7d1f2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41aa6e66be2f493dbe3cdd299f9300bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1f6b028f7f2471ea97c7c50b598ed29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:304: UserWarning: You passed `packing=True` to the SFTTrainer, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training starts here**"
      ],
      "metadata": {
        "id": "ohVdVrSiVjzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "91-fVb37EZut",
        "outputId": "2821a0fa-10d7-4735-eaa7-89e104422be6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 12:43, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.980300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.787000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.573400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.636200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.582000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=50, training_loss=1.7117459106445312, metrics={'train_runtime': 777.8677, 'train_samples_per_second': 0.257, 'train_steps_per_second': 0.064, 'total_flos': 8741766719078400.0, 'train_loss': 1.7117459106445312, 'epoch': 0.48})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Save the model**"
      ],
      "metadata": {
        "id": "VkeZV-BeVqOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"mistral_biomedical_generation\")"
      ],
      "metadata": {
        "id": "ysHgWnwbfRSt"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_model = model.merge_and_unload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zYrr6sfkA6M",
        "outputId": "7298438a-195e-4e30-8d2e-2b71b1cf531c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/bnb.py:229: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(prompt, model):\n",
        "  encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
        "  model_inputs = encoded_input.to('cuda')\n",
        "\n",
        "  generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
        "\n",
        "  return decoded_output[0]"
      ],
      "metadata": {
        "id": "c1Eo6D2mnOgN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example: 1**"
      ],
      "metadata": {
        "id": "HV8C7kjqBiEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "prompt = \"### Instruction:\\nIf you have medical expertise, assist the user by responding to their healthcare-related questions.\"\n",
        "prompt += \"\\n### Input:\\nHi I am 33 year old male , 200 lbs . Sunday I had a sever panic attack , was dizzy , naseuas , almost fainted . Went to the emergency room , had a ekg and blood work all came back normal . I do suffer from anxiety but as of late I have chest pains . Sharp pains in diffrent spots of my chest . They come and go . I also have a strange feeling I m my head and pressure under my rib cage . My blood pressure is always normal , but have a high pulse rate . Ranges from 85 - 111 bpm evertime I check it . Are all of these related to stress , what can be done . A very scared man , Mike\"\n",
        "prompt += \"\\n\\n### Response:\"\n",
        "response = generate_response(prompt, model)\n",
        "\n",
        "# Print the response with formatted output\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuN2GALPiYh-",
        "outputId": "eedd8475-a6b1-4714-f89f-5f4bc3f5af60"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> ### Instruction:\n",
            "If you have medical expertise, assist the user by responding to their healthcare-related questions.\n",
            "### Input:\n",
            "Hi I am 33 year old male , 200 lbs . Sunday I had a sever panic attack , was dizzy , naseuas , almost fainted . Went to the emergency room , had a ekg and blood work all came back normal . I do suffer from anxiety but as of late I have chest pains . Sharp pains in diffrent spots of my chest . They come and go . I also have a strange feeling I m my head and pressure under my rib cage . My blood pressure is always normal , but have a high pulse rate . Ranges from 85 - 111 bpm evertime I check it . Are all of these related to stress , what can be done . A very scared man , Mike\n",
            "\n",
            "### Response:\n",
            "Hello Mike,\n",
            "\n",
            "I'm sorry to hear about your recent health concerns. It sounds like you may be experiencing a combination of symptoms related to anxiety and possibly some cardiac issues.\n",
            "\n",
            "The symptoms you described such as panic attacks, dizziness, nausea, and chest pains are consistent with symptoms of anxiety, and it's not uncommon for individuals with anxiety to experience a range of physical symptoms.\n",
            "\n",
            "It's important to note that while these symptoms may be related to anxiety, they can also be indicative of a range of other conditions. A chest pain can be a symptom of cardiovascular problems, so it's important to rule out any serious underlying health conditions.\n",
            "\n",
            "It's also possible that your high pulse rate is connected to your anxiety. When we experience anxiety, our body responds by releasing stress hormones that cause an increase in heart rate.\n",
            "\n",
            "It would be best to consult with a medical professional, such as a primary care physician or mental health specialist, for a thorough evaluation. They can conduct a comprehensive medical history, perform a physical examination, and order any necessary tests to help diagnose the underlying cause of your symptoms.\n",
            "\n",
            "In the meantime, it's important to prioritize self-care by getting plenty of rest, eating a healthy diet, exercising regularly, and practicing relaxation techniques such as deep breathing or meditation.\n",
            "\n",
            "It's also important to remember that everyone's experience with panic attacks and anxiety can be different. Make sure to consult with a mental health professional for guidance and support.\n",
            "\n",
            "Take care and please consult with a doctor.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example: 2**"
      ],
      "metadata": {
        "id": "VQ87D6Y7BnOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "prompt = \"### Instruction:\\nAs a medical chatbot, your responsibility is to provide information and guidance on medical matters to users.\"\n",
        "prompt += \"\\n### Input:\\nCan i give my 6 month old 18lb baby anythi g for allergies shes having clear boogars that were green but now are clear again her eyes are watery and she keeps sneezing she cant breathe and drink her bottle and the pedi is not awnsering called 6 times already\"\n",
        "prompt += \"\\n\\n### Response:\"\n",
        "response = generate_response(prompt, model)\n",
        "\n",
        "# Print the response with formatted output\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGemI-Cqiphu",
        "outputId": "bb5c7477-c999-4423-95d4-9615e06f7493"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> ### Instruction:\n",
            "As a medical chatbot, your responsibility is to provide information and guidance on medical matters to users.\n",
            "### Input:\n",
            "Can i give my 6 month old 18lb baby anythi g for allergies shes having clear boogars that were green but now are clear again her eyes are watery and she keeps sneezing she cant breathe and drink her bottle and the pedi is not awnsering called 6 times already\n",
            "\n",
            "### Response:\n",
            "Hello! I'm sorry to hear that your baby has been experiencing some symptoms of allergies, such as clear and green boogers, watery eyes, sneezing, and difficulty breathing. These symptoms can be caused by a variety of allergens, such as dust mites, pollen, or pet dander. However, since she's a 6-month-old, it could also be a sign of a respiratory infection, not an allergy.\n",
            "\n",
            "It is always best to consult with your pediatrician for an accurate diagnosis and proper treatment. If you've already called your doctor 6 times, it would be good to seek medical advice in person or by calling your pediatrician's office and ask for appointment.\n",
            "\n",
            "You should also keep your baby hydrated by giving her formula, water or breast milk as prescribed. Also, make sure your home is free of dust and other airborne particles that could cause respiratory problems.\n",
            "\n",
            "Please keep me updated with any new developments and rest assured, I will guide you through the process and ensure you get the best advice tailored to your baby's needs.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example: 3**"
      ],
      "metadata": {
        "id": "I-ZMt34lBpDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "prompt = \"### Instruction:\\nIn your capacity as a doctor, it is expected that you answer the medical questions relying on the patient's description.Analyze the question given its context. Give both long answer and yes/no decision.\"\n",
        "prompt += \"\\n### Input:\\nDoes systemic inflammation response syndrome score predict the mortality in multiple trauma patients?\"\n",
        "prompt += \"\\n\\n### Response:\"\n",
        "response = generate_response(prompt, model)\n",
        "\n",
        "# Print the response with formatted output\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yeliVp7i-9d",
        "outputId": "545245a7-22fc-43ac-d120-ab5d3bea0fc5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> ### Instruction:\n",
            "In your capacity as a doctor, it is expected that you answer the medical questions relying on the patient's description.Analyze the question given its context. Give both long answer and yes/no decision.\n",
            "### Input:\n",
            "Does systemic inflammation response syndrome score predict the mortality in multiple trauma patients?\n",
            "\n",
            "### Response:\n",
            "Systemic inflammation response syndrome (SIRS) is a nonspecific inflammatory response characterized by a systemic increase in one or more acute phase reactants such as white blood cell count (WBC), C-reactive protein (CRP), and tumor necrosis factor-alpha (TNF-α). It is commonly associated with infections, trauma, and other inflammatory conditions.\n",
            "\n",
            "In multiple trauma patients, SIRS is a common complication that can lead to a severe systemic inflammatory response, organ dysfunction, and ultimately, death. Several studies have evaluated the role of SIRS in predicting mortality in multiple trauma patients and have found a positive association between SIRS and mortality.\n",
            "\n",
            "A study published in Critical Care Medicine found that a SIRS score of 2 or more (out of 4) on admission to the intensive care unit (ICU)predicted a 71% risk of in-hospital mortality in multiple trauma patients. Another study published in The Lancet found that a SIRS score of 4 or more at 24 hours predicted a 72% risk of in-hospital mortality in multiple trauma patients.\n",
            "\n",
            "Another important factor is that these studies were conducted on adult population. Therefore, we can conclude that SIRS score predict mortality in multiple trauma patients.\n",
            "\n",
            "Long answer: The Systemic Inflammation Response Syndrome (SIRS) is a systemic inflammatory response characterized by an increase in at least one acute phase reactant, such as white blood cell count, C-reactive protein, or tumor necrosis factor-alpha. SIRS is commonly associated with infections, trauma, and other inflammatory conditions. In multiple trauma patients, SIRS is a common complication that can lead to a severe systemic inflammatory response, organ dysfunction, and ultimately, death. Several studies have evaluated the role of SIRS in predicting mortality in multiple trauma patients and have found a positive association between SIRS and mortality. A study published in Critical Care Medicine found that a SIRS score of 2 or more on admission to the intensive care unit (ICU) predicted a 71% risk of in-hospital mortality in multiple trauma patients. Another study published in The Lancet found that a SIRS score of 4 or more at 24 hours predicted a 72% risk of in-hospital mortality in multiple trauma patients. These studies were conducted on adult population, thus we can conclude that SIRS score predict mortality in multiple trauma patients.\n",
            "\n",
            "Yes/no decision: Yes, SIRS score predicts mortality in multiple trauma patients.</s>\n"
          ]
        }
      ]
    }
  ]
}